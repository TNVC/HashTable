# Тема: Исследование возможностей оптимизации ПО на примере хеш-таблицы
### Направление: "Введение в эмуляцию вычислительных систем, компиляторные технологии и промышленное программирование"
**Выполнил Буторин Даниил**
## Цель
Изучить различные реализации хеш-функций, изучить их дисперсию; исследовать реализацию инфроструктуры хеш-таблтцы на предмет возможных оптимизаций, внедрение найденных решений, вычисление коэффициента полезного прироста производительности ассемблерной оптимизации.
## В работе используются
Язык программирования C\C++; набор компиляторов GCC; инструмент callgrind утилиты valgrind; инструмент визуализации KCachegring.
## Экспериментальная установка
Ноутбук фирмы "Honor" на процессоре "AMD Ryzen 5 5500U with Radeon Graphics" с OS "GNU/Linux 22.04.1-Ubuntu x86_64".
## Теоретическая справка:
Хеш-функция — функция, осуществляющая преобразование массива входных данных произвольной длины в выходную битовую строку определенной длины(также называемую ключем). Возвращаемые хеш-функцией значения менее разнообразны, чем входные значения. Случай, при котором хеш-функция преобразует более чем одно значение входных данных в одинаковые ключи, называется "коллизией". Вероятность возникновения коллизий используется для оценки качества хеш-функций.

Ассоциативный массив — абстрактный тип данных, позволяющий хранить пары вида (ключ, значение). Реализация ассоциативного массива может быть представлена хеш-таблицей с разрешением коллизий путем цепочек(каждая ячейка - односвязанный список).

Заселенность хеш-таблицы - среднее количество элементов, приходящихся на каждую ячейку таблицы.

## Ход работы
### _Глава первая. Исследование дисперсии хеш-функций._
> Так как вычисляемая дисперсия распределения хеш-функций зависит от размеров хеш-таблицы,
> то выберем ее размеры оптимальным путем для текущей задачи: заселенность таблицы будет 10-15 элементов.

> Хеш-таблица будет представлена интерфейсом ассоциативного массива с типом (`String`, `String`).

Далее будет приведены разные реализации хеш-функции с их описанием и дисперсией в случае близкого к равномерному распределения(тогда дисперсия будет наименьшей).
Все реализации имеют следующую сигнатуру.
```clike=
typedef uint32_t Hash;
Hash GetHash(const char *value);
```
#### Хеш-функия №1: Эквивалентная константе.
```clike=
Hash GetHash(const char *value)
{
    return CONSTANT_VALUE;
}
```
Хеш-функия возвращает константу для каждого полученного значения.
Самая легкая реализация, но функция обладает крайней неэффективностью.
Неприменима.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23ConstHash%23607.png?raw=true)

</details>

#### Хеш-функия №2: Длина значения.
```clike=
Hash GetHash(const char *value)
{
    return strlen(value);
}
```
Хеш-функия возвращает длину полученного значения. Очевидно, для задач с похожей длиной ключей неэффективна(например: хранение пар имя-фамилия).
Неприменима.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23LengthHash%23607.png?raw=true)

</details>

#### Хеш-функия №3: Сумма элементов значения.
```clike=
Hash GetHash(const char *value)
{
    Hash hash = 0;
    size_t size = strlen(value);
    for (size_t i = 0; i < size)
        hash += value[i];
    return hash;
}
```
Хеш-функия возвращает сумму элементов полученного значения. Распределение данной реализации будет зависеть от диапазона значений элемента значения и средней длины значений.
Имеет лучшее распределение, чем все предыдущие реализации, но качество распределения сильно зависет от набора данных.
Непреминима.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23SummaryHash%23607.png?raw=true)
![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23SummaryHash%2313441.png?raw=true)

</details>

#### Хеш-функия №4: Среднее значение элемента.
```clike=
Hash GetHash(const char *value)
{
    Hash hash = 0;
    size_t size = strlen(value);
    for (size_t i = 0; i < size)
        hash += value[i];
    return hash/size;
}
```
Хеш-функия возвращает среднее значение элемента полученного значения. Распределение данной реализации пиками будет совпадать с частотностью элементов.
Распределение будет зависеть от частотности элементов значений.
Непренимима.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23SummaryLengthHash%23607.png?raw=true)

</details>

#### Хеш-функия №5: Сумма элементов значения при циклическом сдвиге вправо.
```clike=
Hash GetHash(const char *value)
{
    Hash hash = 0;
    size_t size = strlen(value)
    for (size_t i = 0; i < size)
        hash = ROR(hash) + value[i];
    return hash;
}
```
Хеш-функия возвращает сумму элементов полученного во время циклического сдвига вправо. Данная реализация имеет хорошее распределение.
Приемлема для использования.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23RORHash%23607.png?raw=true)
![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23RORHash%2313441.png?raw=true)

</details>

#### Хеш-функия №6: Сумма элементов значения при циклическом сдвиге влево.
```clike=
Hash GetHash(const char *value)
{
    Hash hash = 0;
    size_t size = strlen(value);
    for (size_t i = 0; i < size)
        hash = ROL(hash) + value[i];
    return hash;
}
```
Подобна предыдущей реализации, только циклический сдвиг происходит влево.
Приемлема для использования.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23ROLHash%23607.png?raw=true)
![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23ROLHash%2313441.png?raw=true)

</details>

#### Хеш-функия №7: CRC.
```clike=
Hash GetHash(const char *value)
{
    Hash hash = 0;
    size_t size = strlen(value);
    for (size_t i = 0; i < size)
    {
        for (bit bitValue : value[i])
            hash = ROR(hash) + bitValue;
        if (NeedXor(hash))
            hash ^= POLINOM;
    }
    return hash;
}
```
Алгоритм данной хеш-функции можно описать как полиномиального деления(вместо деления - исключающее или) в столбик.
Приемлема для использования.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23CRCHash%23607.png?raw=true)
![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23CRCHash%2313441.png?raw=true)

</details>

#### Хеш-функия №8: GNU.
```clike=
Hash GetHash(const char *value)
{
    Hash hash = START_VALUE;
    size_t size = strlen(value);
    for (size_t i = 0; i < size)
        hash = (hash >> 5 + hash) + value[i];
    return hash;
}
```
Алгоритм данной хеш-функции использует линейную комбинацию элементов значения с коэффициентами, полученными перемножением простых чисел.
Приемлема для использования.

<details>
<summary> Распределение хеш-функции  </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23GNUHash%23607.png?raw=true)
![alt text](https://github.com/TNVC/HashTable/blob/master/plots/DefaultTable%23O3%23GNUHash%2313441.png?raw=true)

</details>

#### Итоги главы

Так как только у последних четырех реализаций хорошие(малые) дисперсии, то только они и будут отраженны в гистограммах.

![alt text](https://github.com/TNVC/HashTable/blob/master/plots/HashDispertion.png?raw=true)


### _Глава вторая. Оптимизация работы хеш-таблицы._

В данной главе мы будем соревноваться с опцией O3. Мы посмотрим, насколько хорошо она оптимизирует код, и попробуем оптимизировать код лучше.

Для тестирования модели была выбрана GNU реализация хеш-функции из-за наилучшего(наименьшего) показателя дисперсии.
Программы будут собираться с помощью компилятора g++ с опцией O0.

Размер модели базы данных - 163.900 уникальных пар (строка:строка).
Размер модели хеш-таблицы - 13.441 ячеек.

Тестирование будет проходить следующим образом:
- Загрузка базы данных в хеш-таблицу
- Поиск заранее предопределённого набора данных в хеш-таблице(общее количество вызова функции поиска - 1.000.000)
- Очистка хеш-таблицы

#### Оптимизация №0: Изначальная реализация.
Замерим изначальные характеристики модели для последующего сравнения.

<details>
<summary> O0 </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%230_start/0.png?raw=true)

</details>

 Также представим результаты для опции O3, для будущего сравнения.

<details>
<summary> O3 </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%230_start/3.png?raw=true)

</details>

Как видно больше всего инструкций приходится на `GetHash` и среднее количество инструкций на один вызов составляет 170,2.

Можно предположить, что ассемблерный код, сгенерированный компилятором не является эффективным. И смотря на O3 версию, можно сделать вывод, что так и есть.
Из решения данной проблемы можно либо реализовать свою ассемблерную версию или использовать ассемблерную вставку.

Было предположение, что ассемблерная вставка будет медленней из-за формирования стекового кадра, но для интереса были проверенны все версии.

#### Оптимизация №1: Замена реализации хеш-функции.

<details>
<summary> Asm </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%231_asmHash/asm.png?raw=true)

</details>

<details>
<summary> Inline asm with O0 </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%231_asmHash/inlineO0.png?raw=true)

</details>

<details>
<summary> Inline asm with O1 </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%231_asmHash/inlineO1.png?raw=true)

</details>

Отметим улучшения:

(Здесь и далее будет сравниваться версии с опцией O0)

(Абсолютный прирост - прирост производительности относительно начального измерения)

(Относительный прирост - прирост производительности относительно предыдущего измерения)

- Абсолютный прирост(для Asm): 1,19
- Абсолютный прирост(для Inline asm with O0): 1,28
- Абсолютный прирост(для Inline asm with O1): 1,29

Также посчитаем коэффициент полезного прироста производительности ассемблерной оптимизации(больше - лучше):
- (для Asm): 91,5
- (для Inline asm with O0): 98,5
- (для Inline asm with O1): 99,2

Код ассемблерной вставки и ассемблерной реализации идентичен.

На удивление, версия с ассемблерной вставкой лучше, чем с ассемблерной реализацией. В случае с опцией O1 единственное отличие ассемблерной вставки и ассемблерной реализациею - наличие инструкции `endbr64`, и как мы видим общее количество инструкций в данной версии функции `GetHash` сократилось на 8M, а также общее количество инструкций было меньше на 50M. Но самое интересное, что версия ассемблерной вставки с опцией O0, где кроме `endbr64` был и стековый кадр, но и при этом `GetHash` содержало на 2M меньше, а общее количество уменьшилось на 44M инструкций.

Дальше будет использоваться версия Inline asm with O1(O1 только для данной функции).

Теперь можно проанализировать полученные результаты. Первое место занимает функция `Get`. Так как в самой функции нет явных проблемных мест, то для оптимизации можно уменьшить нагрузку на функцию путем увелечения размера таблицы до 112.111 ячеек.

#### Оптимизация №2: Увеличение размеров таблицы.

В данной оптимизации размер таблицы будет увеличен с 13.441 до 112.111.

<details>
<summary> Результаты замеров </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%232_newSize/0.png?raw=true)

</details>

Отметим улучшения:

- Абсолютный    прирост: 2,20
- Относительный прирост: 1,70

Первые два пункта занимают функции, которые уже были оптимизированы(и на данный момент в них нечего оптимизировать), поэтому они будут пропущены.

В таком случае стоит рассмотреть `__strcmp_avx2`. Данная функция присутствует в рейтинге из-за факта неравномерности длины строк, также по данной причине в списке видна и функция `__strchr_avx2`.
Данную проблему можно решить путем подмены типа данных. Вместо строк произвольной длины с терминирующем символом - строки фиксированной длины без терминирующего символа. В данном случае в поиски при сравнении ключей можно будет использовать `_mm256_testc_si256`, что решит вопрос использования `__strcmp_avx2`. Но для решения вопроса использования `__strchr_avx2` можно нормировать базу данных - перевести ее из текстового формата в бинарный. Перевод таблицы будет происходить следующим образом - строки меньше 32 символов будут увеличены до 32 путем добавления нулевых символов, а строки длинней - путем отсекания.

#### Оптимизация №3: Подменна типов ключа и значения, нормирование базы данных.

<details>
<summary> Результаты замеров </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%233_newType/0.png?raw=true)

</details>

Отметим улучшения:

- Абсолютный    прирост: 2,39
- Относительный прирост: 1,09

Тут можно подметить, что относительный прирост мал, но еще значим.

Так как теперь размер ключа - фиксированное значение, то можно попробовать заменить хеш-функцию на одну из аппаратно поддерживаемых. Среди таких есть ранее нам знакомый CRC32. Хоть у него и более плохая дисперсия, но вместо цикла по всем 32 элементам строки, можно использовать четыре инструкции обрабатывающие по 8 символов за один раз.

Хоть раньше и было зафиксировано, что ассемблерная вставка дает лучший прирост производительности при O0, чем ассемблерная реализация, но для эксперимента было принято решение использовать именно ассемблерную реализацию.

Для справки, также в самом конце была реализована и ассемблерная вставка. Было замечено, что при O0 количество инструкций в `GetHash` было увеличено на 1M, но общее количество уменьшилось на 32M. При этом при опции O3 общее количество инструкций увеличилось на 2M. Так что данное решение было правильным.

#### Оптимизация №4: Повторная замена реализации хеш-функции.

<details>
<summary> Результаты замеров </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%234_newAsm/0.png?raw=true)

</details>

Отметим улучшения:

- Абсолютный    прирост: 3,18
- Относительный прирост: 1,45

Также посчитаем коэффициент полезного прироста производительности ассемблерной оптимизации:

- Для    абсолютного: 397.5
- Для относительного: 181.25

Пропустим `Get`, по уже ранее описанным причинам. Следующая функция `AreKeysEqual`(объявлена как inline) оптимизации не подлежит, так как сводится к вызову встраиваемой функции `_mm256_testc_si256`, но из-за опции O0 ее вставка не была произведена.

Поэтому рассмотрим `_int_malloc`. Также просмотрев список, можно заметить и другие функции работы с динамической памяти. Проанализируем текущий принцип использования динамической памяти. На данный момент память представляет собой много разбросанных малых кусков, соединенных принципом цепочки. Так как время выполнения `calloc` линейно зависит от количества выделенной памяти(во всей программе), а также и `DestroyHashTable`(для решения коллизий списками) линейно зависит от количества элементов в таблице, то данные факторы будут сильно замедлять работу при большой базе данных и/или частом использовании пользователем `malloc/calloc`. Было решено использовать свои функции работы с динамической памятью, которые будут работать в заранее заказанной большой области памяти, которая будет определяться по размеру таблицы. Наша реализация будет совпадать со стандартной, но с отличием в том, что все выделяемые области памяти имеют один размер. Также очистка динамической памяти будет сведена к одному вызову `free`.

Но у данного решения есть важный недостаток - заполнение буфера.

При наступлении данного события можно:
- Увеличить размер таблицы, что влечет пересчитывание адресов для каждого элемента
- Выдавать ошибку переполнения буфера

Был принят второй вариант, и добавлен дисклеймер, что максимальное количество элементов, которые можно поместить в таблицу, равно `table.size * SIZE_FACTOR`. Так как рекомендую подбирать размер таблицы, чтобы в среднем на одну ячейку приходилось 1-2 элемента, то можно взять `SIZE_FACTOR` как 2 или 3.

#### Оптимизация №5: Замена стандартных функций работы с динамической памятью.

<details>
<summary> Результаты замеров </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%235_newMalloc/0.png?raw=true)

</details>

Отметим улучшения:

- Абсолютный    прирост: 4,03
- Относительный прирост: 1,27

Далее смотря на таблицу явно не видно, что можно оптимизировать. Но всегда можно использовать O3.

<details>
<summary> O3 </summary>

![alt text](https://github.com/TNVC/HashTable/blob/master/callgrind/%235_newMalloc/3.png?raw=true)

</details>

Из возможных оптимизаций - параллейная загрузка базы данных. Но создание и уничтожение потоков - ресурсоемкие операции. Также в данной работе мы замеряем количество инструкций, а не время исполнения. Поэтому данная оптимизация нас не интересует.

Так как не ясно, что можно оптимизировать(чтобы уменьшить количество), то было принято решение прекратить серию оптимизаций и посчитать результаты.

#### Итоги главы

Будем сравнивать изначальные характеристики с последним тестированием.

Прирост производительности версий с разными оптимизациями:
| Версии для сравнения | Прирост     | Коэф. прироста производительности |
| -------------------- | ----------- | --------------------------------- |
| Start(O0):Start(O3)  | 1,64        |    0,0                            |
| Start(O0):End(O0)    | 4,03        |  575,7                            |
| Start(O0):End(O3)    | 9,60        | 1371,4                            |
| Start(O3):End(O3)    | 5,85        |  835,7                            |

#### Итоги
- Оптимизации только флагами компилятора может быть недостаточно
- Уход от более свободных рамок к более строгим может дать значимый прирост производительности

Но остается открытым вопрос, чем стоит жертвовать при оптимизации - памятью или производительностью(в данной работе было выбрано первое). Так как память - всегда дефицитный ресурс, то при факте загрузки всего файла в память, то увеличение базы данных с 7MB до 10,5MB(то есть в 1,5 раза) может быть значимым при большем размере базы данных. Но это уже другой вопрос.
